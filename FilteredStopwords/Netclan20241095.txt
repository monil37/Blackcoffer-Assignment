ETL Solution for Currency Data to Google Big Query Client Background Client: A Leading Tech Firm the USA Industry Type: IT Consulting Services: Software, Consulting Organization Size: 100+ Project Objective Fetch currency data Pure-clear API and store it to Google BigQuery. Create a Google function to automate the above process. Project Description We have given a pure-clear API and a google account. We need to fetch currency data that pure-clear API using python and need to store fetched data Google Bigquery. We also need to automate the above process like the process runs on a basis and update the currency data on Bigquery. Our Solution We have created a python program that can fetch pure-clear API data. The API data was JSON format but we needed table format we used python package pandas. We converted json data to tabular format using pandas. After that, we connected python code to google using google’s authentication module and then stored data (table) directly to BigQuery using the “.to_gbq” method. We also need to run the above process to update data BigQuery. For this Google provides a “Cloud function” tool. this, we can create a function and set up their running process. we created a function and attached the above code to that function and set up a function to run daily. Project Deliverables A Google function that runs and updates data on Google BigQuery Tools used function, BigQuery of Google Cloud, Google Colab notebook, Python programming, Pandas Language/techniques used Python language and pandas module Skills used Python programming, Data handling, Google Databases used Google BigQuery Web Servers used Google Server What are the technical Challenges Faced during Project Execution Connecting google to python code is challenging because Its credentials should be a specified format otherwise it shows authentication error. How the Technical Challenges were Solved To tackle this challenge we created a dictionary format (key-value pair) and stored all the authentication variables the dictionary as a value pair. Then we used google’s authentication library “google.auth” and passed a dictionary to the service_account method and stored it different variables we can store data pandas dataframe to Google BigQuery. Project Snapshots 
Datawarehouse, and Recommendations Engine for AirBNB Client Background Client: A leading hotels chain the USA Industry Type: Estate, Hospitality Services: Hostpitality Organization Size: 1000+ Project Objective To download the data the servers using Cyberduck on the basis and perform data engineering on it. Project Description Firstly, download the property and forward files the server Secondly, the property master file a data set was created with the conditions that the Bedrooms Property file should be 5 or or Guests Property File should be 16 or and City Property File should be Sevierville or Pigeon Forge or Gatlinburg. the forward file only those with status = R were kept and the other data was removed. Finally, forward file was merged with the data set on ‘Property ID’ i.e., keeping only those forward data with the common ‘Property ID’ and City, Bedrooms, Guests columns the dataset was added to the forward file. Our Solution We created a Python Script which performs the task and create property and forward master files, which we deliver to client on weekly basis. Project Deliverables Two csv files named property master file and forward master file to be delivered weekly after applying various steps. Tools used PyCharm, PowerBi, Cyberduck, Microsoft Excel. Language/techniques used Python Programming Language is used to create scripts performing Data Manipulation different files. Models used SDLC is a process followed for a software project, within a software organization. It consists of a detailed plan describing how to develop, maintain, replace and alter or enhance specific software. The life cycle defines a methodology for improving the quality of software and the overall development process. We are using Iterative Waterfall SDLC Model as we have to follow our development of software phases and we also need feedback on every step of the development of our project as to keep track of the occurring changes with every step. Figure 1 SDLC Iterative Waterfall Model Skills used Skills such as Data Pre-processing, cleaning, and data manipulation are used this project. Databases used We used traditional of storing the data i.e file systems. Web Servers used Cyberduck, which is a libre server and storage browser for and Windows with support for FTP, SFTP, WebDAV, Amazon S3 etc, was used this project with Amazon S3 servers. What are the technical Challenges Faced during Project Execution? Data to be processed was very big size, space complexity was a challenge this project How the Technical Challenges were Solved To solve the space complexity issues, we tried PowerBi, but now time complexity arises. Then we did processing chunks, by reducing file sizes to avoid memory errors. Project Snapshots (Minimum 10 Pictures) 